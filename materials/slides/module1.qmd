---
title: "CMPT 419 E200: H&D AI"
date: "2024-01-15"
author: "Prof. Nick Vincent"
institute: "Simon Fraser University"
format:
  revealjs:
    chalkboard: true
jupyter: python3
---

# About

This deck contains lecture content for Jan 15, 2024 and Jan 24, 2024.

## {auto-animate=true auto-animate-easing="ease-in-out"}

::: {.r-hstack}
::: {data-id="box1" auto-animate-delay="0" style="background: #00ff9f; width: 200px; height: 150px; margin: 10px;"}
:::

::: {data-id="box2" auto-animate-delay="0.1" style="background: #00b8ff; width: 200px; height: 150px; margin: 10px;"}
:::

::: {data-id="box3" auto-animate-delay="0.2" style="background: #001eff; width: 200px; height: 150px; margin: 10px;"}
:::

::: {data-id="box4" auto-animate-delay="0.2" style="background: #bd00ff; width: 200px; height: 150px; margin: 10px;"}
:::

:::

## {auto-animate=true auto-animate-easing="ease-in-out"}

::: {.r-stack}
::: {data-id="box1" style="background: #00ff9f; width: 350px; height: 350px; border-radius: 200px;"}
:::

::: {data-id="box2" style="background: #00b8ff; width: 250px; height: 250px; border-radius: 200px;"}
:::

::: {data-id="box3" style="background: #001eff; width: 150px; height: 150px; border-radius: 200px;"}
:::

::: {data-id="box4" style="background: #bd00ff; width: 50px; height: 50px; border-radius: 200px;"}
:::
:::


# Block 1

For the Spring 2024 term, this was presented on 2024-01-15.

# While we file in

- Check out Piazza link (Canvas announcements)
- Anyone have AI-related news they want to discuss
- Feel free to collect your thoughts re: strong reactions to readings

# Administrivia

- Tentative course calendar on Canvas updated
- Slides will go on GitHub
- Submit reading response by Wed. this week (or email me if you just joined)
- New readings posted

# Agenda

- Today: Discuss readings for this week
- Goals: highlight key takeaways, find areas of interest
- At the end: Intro to readings for next week

# HCML Reading (Chancellor 2023)

## Good and bad uses of AI -- some go to examples

::: {.incremental}
- Auto complete
- Predict malignant tumor
- Deep fake
- Discrimination (on many axes)
:::

## Progress? in AI

:::: {.columns}
::: {.column width="25%"}
- Deep learning "gains" don't always hold up to scrutinty
:::

::: {.column width="70%"}
![](figs/worrying_trends.png)
:::
::::


::: aside
There are more examples we can discuss! And of course we can keep an eye out for new research news.
:::


## People as "objects of prediction"

- How to counter this?
  - Fairness, equality, justice
- Note: computing often forces us to precisely define these concepts in a way that's illuminating
- We might disagree


## Sub-fields of CS

Article mentions we should "refine HCML into a unifying and interdisciplinary force across CS rather than risk fracture with each sub-field of CS taking ownership of an independent vision of HCML"

What's the backstory here?

## A bit of behind the scenes into CS research

- Subcommunities often run their own conferences
- Drives a lot of the incentives of researchers
- This might matter for research-related jobs in industry too
- e.g., some ML jobs list NeurIps papers as a requirement, some Responsible AI jobs list FAccT

## Examples

- ML people send papers to NeurIPS, ICML, ICLR, and many more
- HCI people send papers to CHI, CSCW, and many more
- Philosophy people send papers to their own, pretty much entirely separate journals

## Early HCML

- Chancellor highlights some of the history -- the "HCI" community and "FAccT" community played major roles
  - FAccT is a relatively new conference which has gained a lot of momentum
- Information Science and STS
- CSCW also plays a major role
- Various social sciences and fields of critical scholarships as well..
- That's a lot of disciplines already

## Acronym Cheatsheet thus far

- HCI: human-computer interaction. Main conference is "CHI", confusingly.
- FAccT: Fairness, Accountability, and Transparency
- CSCW: computer supported cooperative work (and social computing)
- [STS](https://en.wikipedia.org/wiki/Science_and_technology_studies): Science and technology studies. Also, science, technology, and society
 
# What Counts as HCML?

## Proposed definition statement

"Human-centered machine learning is a set of practices for building, evaluating, deploying, and critiquing ML systems that balances technical innovation with an equivalent focus on human and social concerns."^[[Chancellor 2023](https://cacm.acm.org/magazines/2023/3/270209-toward-practices-for-human-centered-machine-learning/fulltext)]

## We can evaluate different practices to see if they fit in this set

- It's possible two different organizations both trying to build an AI system for the same *task* could differ substantially in whether they meet the "human-centered" definition
- People can always disagree about what human and social concerns should be ranked most highly
- But this gives us a starting point

## Focusing on Practices 

Five categories of suggestions are given, i.e. what can you do when you're a software engineer, manager, research scientist, professor, etc.

- should I use ML?
- what's my "position"? ^[See e.g. [positionality statements](https://en.wikipedia.org/wiki/Positionality_statement)]
- users vs. humans
- credit other domains
- iterate on failure

# What challenges might we expect to face?

## Institutional actions

- new norms at conference, e.g. negative impact statements (NeurIPS)
- institutional support for interdisciplinary research
- computing (broad) vs. computer science
- support students who want to do interdisciplinary research!

# Over to DCAI

## Problems with data

- "Differences in labeling": do you and I agree if a pill is "scratched"? Does my hospital notes system have a different coding system than yours?
- "Emphasis on big data": what about a rare medical condition?
- "Ad hoc data curation": need to systemize?

## Finding label disputes

- We might use tools to find subsets of a dataset with high label dispute
- Influence estimation provides one approach we'll see

## Domain Expertise

- get the biologists to label the cells!
- get former players to provide "labels" for sports analytics
- many more examples
- this is where the DCAI argument really starts to merge with the HCAI argument

## More info

- https://www.youtube.com/watch?v=TU6u_T-s68Y


## What is DataPerf

- a so-called "benchmark suite"
- focused on data tasks
- meant to be community run and led 


## What's a "ML benchmark?"

Conventional model-centric ML definition: "a standard, fixed dataset for model accuracy comparisons and per-
formance measurement" (p2, Mazumber et al)

## Some terms

- from "Probabilistic Machine Learning: An Introduction", Murphy 2022 (https://probml.github.io/pml-book/book1.html)
- task $T$ to learn mapping $f$ from inputs $x \in X$ to outputs $y \in Y$
- x called features (or covariates, or predictors)
- y is label (or target, or response)
- we have N input-output pairs $D = {(x_n, y_n)}$ for $n \in (1,N)$. D is the training set, N is the sample size.

## Comparing model-centric benchmark and data-centric benchmark

- in model-centric, we have a fixed dataset $D$ and we try a bunch of different ways to find $f$
- change model architecture, change training hyperparameters, change task metrics
- in data-centric, we keep all these fixed and just change $D$

## Testable concept: is a benchmark data centric

- you might imagine a test question that describes several differents tasks and asks you to identify which one is "data-centric"


## Six data centric operations

data...

- parsing
- augmentation
- selection
- quality assessment
- acquisition
- cleaning

##

Hold time for:

- discuss next week's readings
- questions that have popped up thus far



# Blocks 2-3

## Metadata

For the Spring 2024 term, this was presented on 2024-01-24.

## Agenda

- 2.1 Course logistics
- 2.2 Questions from last time
- 2.3 Reading review: steps in the data pipeline
- 2.4 Quick intro to relevant concepts from other disciplines
- 2.5 Activity: developing some running scenarios for the course
- 2.6 Connections to recent concepts

## 2.1 Course logistics

- Quiz #1 next Wednesday. Will take into account our course disruptions thus far!
- First quiz will also serve to test our logistics and see how things go
- Format: on computers, using Canvas "quiz" feature, any materials allowed, multiple choice and short answer, no code writing, no long form writing
  - may have a some code and long form writing on the final exam only
- each quiz is meant to provide addiitonal structure to our very broad-ranging course
- heuristic I'll use: could you talk about the material in a job interview or research context?

## 2.2 Questions and feedback from last time

- Some in this slide deck, some in G doc

## 

- How is data-centric AI or data-centric ML different just plain old AI or plain old ML? 
- The DataPerf paper provides one way to answer that
- To expand, we might imagine a few *running scenarios* that will be useful throughout our course

## Running scenario 1: you're a startup founder!

- Let's imagine we're each the founder of an AI startup
- We're trying to build one specific product. Perhaps it's a movie recommender system, or computer vision system that looks at pictures of a fridge and suggests a recipe, or a domain-specific chatbot such as a medical assistant
- Core challenge of allocation resources

## A few ideas that try and cut across varied interests!

- ggGPT - A LLM that's broadly useful for a variety of sporting and entertainment-related tasks: simulating an NPC in a game, providing insight on sports strategies, etc.
- MedAssist - A chatbot for mental health support and medical advice (perhaps using multiple models)
- ForYouPlus - a better recommender system for a social media feed that combines news and other content

## How we might allocate resources

- Buy more compute (GPUs, cloud credits, etc)
- Hire more ML research scientists
- Hire more software engineers
- etc.

## Distinction

We can think of a sharp distinction between asking our research scientists to spend more time trying different neural network architectures vs. spending more double-checking that the training data is labeled well.

Or we could hire people to go into the world and get more data. etc.!

## HCAI and DCAI gives us additional options

Sometimes we do just need to buy more GPUs. Almost all the material in this course will help us explore the full set of options.

Part of the point of the DataPerf paper is to say that the ML field thus far has focused too much on trying different models instead of just hiring domain experts to double check your data.

This is in line with the HCML paper.

## Running scenario 2: You're a policymaker!

Here's a very broad question. Say we're trying to draft a new Act that will change how data can be collected or used. For instance, we might want to ask companies to make it easier for users to withhold data.

*What policy will maximize social welfare*

Ok, that's a big question. We'll return to it...

## These scenarios aren't too far off from "IRL" cases

- The most relevant one in the short term is, what do *I* do differently as a software engineer, data engineer, ML research scientist, etc.
- But the options are pretty general

##

- CEO example: is generally about organization decision-making
- a manager or IC faces the same kinds of trade-offs but with less individiual power
- Policymaker example: is generally about setting the "rules of engagement"
- a citizen or voter faces the same kinds of trade-offs but with (much) less individual power

## 

- Understanding the HCAI and DCAI perspective on CEO-decision making will help anyone working in a product-focused org
- Understanding the HCAI and DCAI perspective on policymaker decision making will help anyone contributing to policy (i.e., anyone who votes)


# 2.3 Reading review: data pipeline

The Zha paper gives us another model to describe the full "pipeline" of data. This will be a recurring theme, with some variations!

## Sub-goals

- Collection
- Labeling
- Preparation
- Reduction
- Augmentation

## Product perspective on this

- Worth noting that each of these steps typically requires some kind of feature, separate product, or partner
- Platforms to collect data
- Platforms to label data
- Employee with the job of preparing data (data engineer, probably)
- Employee with the job of reducing data (data scientist, probably)

## 

Quick blackboard diagram on this to clarify!

## Sometimes lines between categories are blurry

- Is collection and labeling always so distinct?

# 2.4 Quick intro to relevant interdisciplinary concents

Goal: just a "Wikipedia tier" exposure

We'll cover more specific aspects as needed.

Caveat: we all must endeavor to keep learning about these things, myself included! ^[There's a running joke about economists and CS folks in particular being guilty of reading the Wikipedia page from another discipline and assuming they know everything about it!]

## Externality

- https://en.wikipedia.org/wiki/Externality
- aka external cost
- "indirect cost or benefit to an uninvolved third party that arises as an effect of another party's (or parties') activity"
- classic example: air polution

## More on externalities

- can be positive or negative
- positive externality: somebody walking by our classroom hears a funny joke you cracked
- can depend on how you're defining the "parties" involved in a transaction ^[a recurring theme we'll see in HCAI and DCAI is the need to be very precise about how we define relevant agents, parties, rules of engagement]

## Externalities and AI

- many AI harms as probably best described as externalities
- generally AI developers, even those who aren't explicitly trying to be "human centered" put some effort into not explicitly harming their users. So the main people being harmed are outside the "user" category
- though there are exceptions (esp. government use of AI)

## Knowledge sharing

- On the positive side, some might argue that AI industry creates some *positive externalities*
- open source software
- search engines and LLMs, if done correctly, have the potential to increase access to knowledge
- recommender help cut through the noise
- genAI help when people have unequal access to resources to practice a language, etc. ^[One currently hot ethical debate centers around the use of genAI to help produce art vs. the use of genAI to help people write in their non-first language.]

## Market failure

- https://en.wikipedia.org/wiki/Market_failure
- "a situation in which the allocation of goods and services by a free market is not Pareto efficient, often leading to a net loss of economic value"
- interconnected with externalities

## Public Goods

- https://en.wikipedia.org/wiki/Public_goods
- "a good that is both non-excludable and non-rivalrous"
- wait a second, what are those?

## 

![](figs/WP_pubgoods.png)

source: https://en.wikipedia.org/wiki/Public_good_(economics)


## Non-excludable goods

- "the degree to which a good, service or resource can be limited to only paying customers"
- or, "the degree to which a supplier, producer or other managing body (e.g. a government) can prevent "free" consumption of a good"
- i.e., how easily can put a fence around this thing
- https://en.wikipedia.org/wiki/Excludability


## Non-rivalrous goods

- "the cost of providing it to a marginal (additional) individual is zero"
- i.e. when you use the thing does it stop me from using the thing
- https://en.wikipedia.org/wiki/Rivalry_(economics)


## 2x2 grid of rivalry and exclude

![](figs/WP_rivexcl.png)

Source: https://en.wikipedia.org/wiki/Goods#Goods_classified_by_exclusivity_and_competitiveness


## Ok, back to public goods

- can be used by multiple people with no problems
- classic examples: knowledge and language, public parks, radio broadcast

## Club goods

- in between public and private
- aka quasi-public goods
- excludable but non-rivalrous (because they get congested at some point)
- classic examples: toll road, private park
- https://en.wikipedia.org/wiki/Club_good

## Public and Club Goods and AI, oh my?

- Data and AI outputs are typically seen as information, and therefore potentially public goods
- Data is naturally non-rival: very cheap to copy and share, in absence of data protection laws
- Data requires effort to exclude: you need to put up anti-scraping measures or threaten me with a lawsuit, or else I'll write a Python script to scrape your website (and then I can copy and share with everybody)


# Crash Course, Some Other Relevant Concepts

##  Norms
- "Normative sentences imply "ought-to" types of statements and assertions"
- https://en.wikipedia.org/wiki/Norm_(philosophy)

## Normative goals

- We might see this in some HCAI and Responsible AI work.
- In short, this relates to different views on how the world ought to be
- Data has a mix of normative preferences and descriptive preferences in it. Can cause all sorts of problems

## Positionality statement

- describe researchers personal position relative to a project
- often focused on group identity (some controversy around this)
- somewhat discipline dependent
- https://en.wikipedia.org/wiki/Positionality_statement


## Moral philosophy

- https://en.wikipedia.org/wiki/Ethics
- try to answer normative questions about what is morally right

## Moral philosophy and AI

- A lot of questions about what kinds of AI systems are morally better than others, and what kinds of processes are morally better than other, are basically part of HCAI
- HCAI often requires a more explicit moral stance than "pre-HCAI" ^[Many people have been talking about HCAI relevant concepts since the inception of computing, to be clear!]
- but note this is because the values in "pre-HCAI" are some kind of rationalist epistemology

## Epistemology?

- https://en.wikipedia.org/wiki/Epistemology
- https://plato.stanford.edu/entries/epistemology/
- What is knowledge, how do we know if we have knowledge?

## One example of being specific about moral analysis

- https://dl.acm.org/doi/abs/10.1145/3531146.3533245
- Is calibration a fairness requirement?: An argument from the point of view of moral philosophy and decision theory, Loi and Heitz
- "For any thorough moral analysis, the meaning of the term “fairness” has to be made explicit and defined properly. For our paper, we equate fairness with (non-)discrimination, which is a legitimate understanding in the discussion about group fairness. More specifically, we equate it with “prima facie wrongful discrimination” in the sense this is used in Prof. Lippert-Rasmussen's treatment of this definition"

# 2.5 Activity: Co-writing our running examples (and moving towards a unified definition of HCAI and DCAI)

Let's say we're going to write up a short sort of "simulation" or "game". We our two scenarios (start up founder and policymaker). We want to define all the actions available to them. Let's use our readings thus far and then get started on the next set of readings.

## Prompts

Prompt: what are distinct actions our CEO agent might take to improve their ML product

Prompt: what are distinct actions regulators might take to maximize the positive impact of AI on society? Which might be seen as "human-centered" and which might be seen as supporting "data-centered" AI


## Goal:

Try to describe actions very precisely and succintly so that we can turn them into Python code for some kind of simulation environment.

# 2.6 H&D AI and various products

## Building AI products

We'll see a lot of focus on the data pipeline components of AI products!

Some specific ideas
- face recognition
- voice-to-text
- classification (everything from malware and fraudulent transactions to earthquakes and health outcomes)
- an "LLM from scratch"

## AI in health care in particular

## AI and games

- reinforcement learning
- interesting connections with data-centric AI!

## Recent ideas in LLM space

- RLHF (reinforcement learning from human feedback)
- RAG (Retrieval Augmented Generation)
- langchain


## Learning to do research

- Practice reading papers
- Research-style code

## Getting data

- web crawling


## Philosophy and AI

- relevant ideas and arguments
- what can philosophy do for AI, esp. data-centric AI?

